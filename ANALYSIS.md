# Analysis Report â€” Lasso Sharp Threshold Simulation

**Author:** Ishan Paul  
**Project:** Unit 2 â€” Simulation Study (Stats 607)  
**Date:** $(Oct 21, 2025)  
**Repository:** [Unit-2-Project-Stats-607-](https://github.com/IshanPaul/Unit-2-Project-Stats-607-)

---

## ğŸ¯ Overview

This report summarizes the empirical simulation results exploring **sharp thresholds** for exact support recovery using the **Lasso estimator**, as first derived by Wainwright (2009).  

The goal is to investigate how **sample size (n)**, **sparsity (k)**, **correlation (Ï)**, **noise (Ïƒ)**, and **signal strength (Î²â‚˜áµ¢â‚™)** influence the probability of perfect model recovery.

---

## ğŸ§® Simulation Design

- **Model:**  
  \( y = X\beta^* + \epsilon, \quad \epsilon \sim N(0, \sigma^2 I_n) \)
- **Design:**  
  \( X_{ij} \sim N(0, \Sigma), \ \Sigma_{ij} = \rho^{|i-j|} \)
- **Lasso penalty:**  
  \( \lambda = c \sigma \sqrt{\frac{2 \log(p-k)}{n}} \)
- **Grid:**  
  - \( p = 1000 \)
  - \( k \in \{20, 50, 200\} \)
  - \( Ï \in \{0.0, 0.3, 0.6\} \)
  - \( Ïƒ \in \{0.1, 0.5, 1.0\} \)
  - \( Î¸ = \frac{n}{2k\log(p-k)} \in [0.5, 2.0] \)

---

## ğŸ“ˆ Key Results

### 1ï¸âƒ£ Recovery Probability vs. Normalized Sample Size (Î¸)
The first set of figures shows the **sharp phase transition** for exact support recovery as Î¸ increases.  
Recovery probability jumps rapidly from near 0 to near 1 around Î¸ â‰ˆ 1.

![Recovery Probability vs Î¸](results/figures/focused_theta_search.png)

---


### 4ï¸âƒ£ Î»-Factor Sensitivity
A focused search over Î» factors (Ïƒ=0.1, k=5) reveals that too small Î» values cause overfitting, while too large Î»s over-regularize.

![Focused Î» Search](results/analysis/focused_lam_search_sigma0.1_k5.png)

---

### 5ï¸âƒ£ Heatmap: Recovery Rate vs Î¸
Higher noise (Ïƒ) lowers the achievable exact recovery rate for any fixed Î».  
The following heatmap visualizes this effect.

![Heatmap Î» vs Î¸](results/analysis/heatmap_theta_b.png)

---


## ğŸ“Š Summary of Findings

| Parameter | Effect on Recovery | Interpretation |
|------------|--------------------|----------------|
| \( n \) | â†‘ â†’ better recovery | More samples cross threshold |
| \( Ï \) | â†‘ â†’ worse recovery | Correlation breaks incoherence condition |
| \( Ïƒ \) | â†‘ â†’ worse recovery | More noise inflates bias |
| \( Î²_{\min} \) | â†‘ â†’ better recovery | Larger signals easier to detect |
| \( Î» \) | Non-monotonic | Balance between sparsity and shrinkage |

---

## ğŸ§  Conclusions

- A **sharp transition** occurs near Î¸ â‰ˆ 1, consistent with Wainwrightâ€™s theory.  
- Recovery becomes unreliable when predictors are highly correlated or signal-to-noise ratio is low.  
- Cross-validated Î» tends to select values that favor prediction over support recovery.  
- Group Lasso and other structured penalties may improve robustness under correlated designs.

---

## ğŸ—‚ï¸ Next Steps

- Extend to **non-Gaussian noise** or **logistic models**.  
- Explore **grouped sparsity** and compare Group Lasso vs standard Lasso.  
- Quantify empirical phase transition width as a function of k and Ï.

---

**Reference:**  
Wainwright, M. J. (2009). *Sharp thresholds for high-dimensional and noisy sparsity recovery using â„“â‚-constrained quadratic programming (Lasso).* IEEE Trans. Info. Theory, 55(5), 2183â€“2202.
